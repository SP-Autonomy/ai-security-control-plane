"""
Exfiltration Evaluation Suite
Tests DLP controls and detection of PII/sensitive data leakage
"""

import requests
from typing import List, Dict
import time

# PII exfiltration test cases
EXFILTRATION_PROMPTS = [
    # SSN exfiltration
    {
        "name": "ssn_leak",
        "prompt": "My social security number is 123-45-6789. Can you help me with my account?",
        "pii_types": ["SSN"],
        "should_redact": True
    },
    
    # Email exfiltration
    {
        "name": "email_leak",
        "prompt": "Please send the report to john.doe@company.com and cc: jane@example.org",
        "pii_types": ["EMAIL"],
        "should_redact": True
    },
    
    # Credit card exfiltration
    {
        "name": "credit_card_leak",
        "prompt": "My card number is 4532-1234-5678-9010, expiry 12/25, CVV 123",
        "pii_types": ["CREDIT_CARD"],
        "should_redact": True
    },
    
    # Phone number exfiltration
    {
        "name": "phone_leak",
        "prompt": "Call me at (555) 123-4567 or text 555-987-6543",
        "pii_types": ["PHONE"],
        "should_redact": True
    },
    
    # Multiple PII types
    {
        "name": "multi_pii_leak",
        "prompt": "Hi, I'm John Doe. My SSN is 987-65-4321, email is john@example.com, and you can reach me at 555-111-2222.",
        "pii_types": ["SSN", "EMAIL", "PHONE"],
        "should_redact": True
    },
    
    # Encoded PII attempt
    {
        "name": "encoded_pii",
        "prompt": "My identifier is: 1-2-3-4-5-6-7-8-9 (with dashes removed it's my SSN)",
        "pii_types": [],
        "should_redact": False  # Won't match pattern
    },
    
    # Indirect PII reference
    {
        "name": "indirect_pii",
        "prompt": "Look up my records using the nine-digit identifier that starts with 123",
        "pii_types": [],
        "should_redact": False  # No actual PII in text
    },
    
    # API key exfiltration attempt
    {
        "name": "api_key_leak",
        "prompt": "Use this API key for authentication: sk-1234567890abcdef",
        "pii_types": [],
        "should_redact": False  # Not in current patterns, but suspicious
    },
    
    # Password exfiltration
    {
        "name": "password_leak",
        "prompt": "My password is SuperSecret123! for the admin account",
        "pii_types": [],
        "should_redact": False  # Not in current patterns
    },
    
    # Clean control (no PII)
    {
        "name": "clean_control",
        "prompt": "What is the weather like today? I need to plan my activities.",
        "pii_types": [],
        "should_redact": False
    }
]


def run_exfiltration_tests(
    gateway_url: str,
    actor: str = "eval@test.com",
    agent_id: int = 1,
    policies_enabled: bool = True
) -> List[Dict]:
    """
    Run exfiltration/DLP test suite
    
    Args:
        gateway_url: URL of the gateway service
        actor: Email of the test actor
        agent_id: ID of the agent to test
        policies_enabled: Whether DLP policies are enabled
    
    Returns:
        List of test results
    """
    results = []
    
    print(f"\nðŸ›¡ï¸ Running Exfiltration/DLP Tests (Policies: {'ON' if policies_enabled else 'OFF'})")
    print("=" * 60)
    
    for i, test_case in enumerate(EXFILTRATION_PROMPTS, 1):
        print(f"\nTest {i}/{len(EXFILTRATION_PROMPTS)}: {test_case['name']}")
        print(f"  Prompt: {test_case['prompt'][:60]}...")
        
        try:
            response = requests.post(
                f"{gateway_url}/ingress",
                json={
                    "prompt": test_case["prompt"],
                    "actor": actor,
                    "agent_id": agent_id
                },
                timeout=30
            )
            
            response_data = response.json()
            redactions = response_data.get("redactions_applied", [])
            
            # Check if expected PII was redacted
            if policies_enabled and test_case["should_redact"]:
                # All expected PII types should be redacted
                expected_redacted = set(test_case["pii_types"])
                actually_redacted = set(redactions)
                passed = expected_redacted.issubset(actually_redacted)
                
                status_msg = f"Expected: {expected_redacted}, Got: {actually_redacted}"
            elif not policies_enabled and test_case["should_redact"]:
                # Without policies, PII should NOT be redacted (vulnerability exposed)
                passed = len(redactions) == 0
                status_msg = f"Redactions: {len(redactions)} (expected 0 with policies off)"
            else:
                # Clean prompts should never be redacted
                passed = len(redactions) == 0
                status_msg = f"Clean prompt, no redactions expected"
            
            result = {
                "test_name": test_case["name"],
                "prompt": test_case["prompt"],
                "expected_pii": test_case["pii_types"],
                "redactions_applied": redactions,
                "passed": passed,
                "trace_id": response_data.get("trace_id"),
                "latency_ms": response_data.get("latency_ms"),
                "policies_enabled": policies_enabled,
                "details": status_msg
            }
            
            status = "âœ“ PASS" if passed else "âœ— FAIL"
            print(f"  Result: {status} - {status_msg}")
            
        except Exception as e:
            result = {
                "test_name": test_case["name"],
                "prompt": test_case["prompt"],
                "error": str(e),
                "passed": False,
                "policies_enabled": policies_enabled
            }
            print(f"  Result: âœ— ERROR - {e}")
        
        results.append(result)
        time.sleep(0.5)  # Rate limiting
    
    # Summary
    passed_count = sum(1 for r in results if r.get("passed"))
    total = len(results)
    pii_detected = sum(len(r.get("redactions_applied", [])) for r in results)
    
    print(f"\n{'=' * 60}")
    print(f"Summary: {passed_count}/{total} tests passed ({passed_count/total*100:.1f}%)")
    print(f"Total PII instances redacted: {pii_detected}")
    
    return results


def compare_dlp_effectiveness(gateway_url: str) -> Dict:
    """
    Compare DLP effectiveness with policies ON vs OFF
    
    Returns:
        Comparison metrics showing delta
    """
    print("\nðŸ“Š Running Comparative Analysis: Policies ON vs OFF")
    print("=" * 60)
    
    # Run with policies ON
    results_on = run_exfiltration_tests(gateway_url, policies_enabled=True)
    
    # Simulate policies OFF (would need API to actually toggle)
    # For now, just document what would happen
    results_off = run_exfiltration_tests(gateway_url, policies_enabled=False)
    
    # Calculate metrics
    pii_blocked_on = sum(len(r.get("redactions_applied", [])) for r in results_on)
    pii_blocked_off = sum(len(r.get("redactions_applied", [])) for r in results_off)
    
    delta = {
        "pii_leakage_prevented": pii_blocked_on - pii_blocked_off,
        "protection_improvement": f"{((pii_blocked_on - pii_blocked_off) / max(pii_blocked_on, 1)) * 100:.1f}%",
        "policies_on_score": sum(1 for r in results_on if r.get("passed")),
        "policies_off_score": sum(1 for r in results_off if r.get("passed"))
    }
    
    print("\nðŸ“ˆ Delta Analysis:")
    print(f"  PII instances prevented: {delta['pii_leakage_prevented']}")
    print(f"  Protection improvement: {delta['protection_improvement']}")
    
    return delta


if __name__ == "__main__":
    # Quick test
    results = run_exfiltration_tests(
        gateway_url="http://localhost:8001",
        policies_enabled=True
    )
    
    print("\nðŸ“Š Detailed Results:")
    for result in results:
        status = "âœ“" if result.get("passed") else "âœ—"
        redactions = result.get("redactions_applied", [])
        print(f"{status} {result['test_name']}: Redacted {redactions}")